{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Linear Regression Model for Salary Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### The following notebook makes use of a linear regression model, a supervised machine learning technique, to predict the future salaries of employees based on the number of years they have worked (univariate linear regression) . Because we are only focusing on the number of years worked as an influencing factor, this is known as univariate linear regression. Linear Regression is based on the straight line equation y = bX + a, where b is the coefficient and a is the constatnt coefficient. \n",
    "\n",
    "##### Notebook Contents \n",
    "##### 1. Exploratory Data Analysis \n",
    "##### 1.1 Data description \n",
    "##### 1.2 Exploratory Data Analysis: the data is also visualized for distributions and checked for linearity to apply the linear regression model. Visualizations are checked for distributions, patterns and outliers \n",
    "\n",
    "##### 2.Linear Regression Model\n",
    "##### 2.1 Sckit learn Linear Regression model : \"Years worked\" is the target value\n",
    "\n",
    "##### 3. Scoring, Predictions and Evaluation\n",
    "##### 3.1 Scoring and Predictions: The model is scored and used to predict the salaries of people with 2, 12 and 80 years work experience, respectively \n",
    "##### 3.2 Model Evaluation: the model metrics are analysed \n",
    "##### 3.3 Model Improvement \n",
    "\n",
    "##### 4. Conclusion \n",
    "##### The analysis conclusion can be found in the write up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Exploratory Data Analysis \n",
    "### Data description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:01.389973Z",
     "start_time": "2019-11-26T15:27:56.598666Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Packages are imported \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt   \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:01.540766Z",
     "start_time": "2019-11-26T15:28:01.418107Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A dataframe is created from the salary data \n",
    "salaries = pd.read_csv(\"salary.csv\")\n",
    "salaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:02.705782Z",
     "start_time": "2019-11-26T15:28:02.693568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "salaries.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:03.445834Z",
     "start_time": "2019-11-26T15:28:03.420683Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nan_salary = salaries[salaries['salary'].isnull()]\n",
    "nan_salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### The null value is replaced with the median salary values of people who have the same number of years worked, degree, position, and gender as the missing salary value. This ensures the profile or demographics are as close as possible to that of the missing value. Also, the Linear Regression model does not handle NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:05.416447Z",
     "start_time": "2019-11-26T15:28:05.402962Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The null value is replaced with an estimated guess\n",
    "estimated_salary = salaries['salary'].loc[(salaries['yearsworked'] == nan_salary['yearsworked'].values[0]) & \n",
    "                            (salaries['degree'] == nan_salary['degree'].values[0]) & \n",
    "                            (salaries['position'] == nan_salary['position'].values[0]) &\n",
    "                            (salaries['male'] == nan_salary['male'].values[0])].median()\n",
    "\n",
    "salaries['salary'].fillna(estimated_salary, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:06.022341Z",
     "start_time": "2019-11-26T15:28:06.012315Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The mean salary for no full years of work experience is calculated \n",
    "salary_with_no_work_experience = salaries['salary'].loc[(salaries['yearsworked'] == 0)]\n",
    "salary_with_no_work_experience.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Exploratory Data Analysis: the data is also visualized for distributions and checked for linearity to apply the linear regression model. Visualizations are checked for distributions, patterns and outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:07.081655Z",
     "start_time": "2019-11-26T15:28:07.068869Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reshape(scalar_series):\n",
    "    '''The following fucntion takes in a sinlge sample of type int or float or a series in order to reshape it\n",
    "    for use during the modelling process and associated methods'''\n",
    "    if type(scalar_series) == float or type(scalar_series) == int:\n",
    "        scalar_series = np.array(scalar_series).reshape(1, -1)\n",
    "        \n",
    "    else:\n",
    "        assert type(scalar_series) == pd.core.series.Series\n",
    "        scalar_series= np.array(scalar_series).reshape(-1, 1)\n",
    "        \n",
    "    return scalar_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:08.385934Z",
     "start_time": "2019-11-26T15:28:07.661662Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the training data in order to see if a similar linear relationship is still observed\n",
    "X = salaries.yearsworked\n",
    "y = salaries.salary\n",
    "\n",
    "plt.title('The relationship between salaries and the number of years worked')\n",
    "sns.regplot(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### The scatterplot above and trendline show that a linear relationship exists between the salaries earned and the number of years worked by employees. This makes the data a good fit for a linear regression model. However the data seems to also present the possibility of categories as seen with the vertical groupings observed along the x-axis (years worked). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:09.693589Z",
     "start_time": "2019-11-26T15:28:09.330977Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The distribution is now visualized\n",
    "sns.distplot(salaries['yearsworked'], kde = True, color = 'red')\n",
    "plt.title('The distribution of the number of Years Worked', fontsize = 18)\n",
    "plt.xlabel('Years Worked (years)', fontsize = 16)\n",
    "plt.ylabel('Frequency', fontsize = 16)\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### What is observed in the distribution above is a bimodal distribution. This implies that there are two different groups of employees within the dataset. There are those who have relatively high salaries despite working for less than 10 years. There is another group of employees who have relatively high salaries having worked more than 20 years. In order to run a model, the data needs to be a normal distribution. This is achieved using standard scaler in order to normalize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Linear Regression Model\n",
    "### Sckit learn Linear Regression model : \"Years worked\" is the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:12.760485Z",
     "start_time": "2019-11-26T15:28:12.754931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = reshape(X)\n",
    "y = reshape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:13.356877Z",
     "start_time": "2019-11-26T15:28:13.347477Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The data is split into a test and training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:13.882484Z",
     "start_time": "2019-11-26T15:28:13.874874Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The test and train sets are scaled\n",
    "scaler = StandardScaler() \n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:14.389332Z",
     "start_time": "2019-11-26T15:28:14.370363Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Scikit Learn is used to train a Linear Regression model\n",
    "lr = LinearRegression()\n",
    "lr_model = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:14.892366Z",
     "start_time": "2019-11-26T15:28:14.882964Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'The model coeffient is {lr_model.coef_} and the model intercept is {lr_model.intercept_}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### The coefficents simply mean that the model line can be plotted using the function f(x) = 822.97x + 40 722.35, where f(x) is the predicted salary value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##  Scoring, Predictions and Evaluation\n",
    "### Scoring and Predictions: The model is scored and used to predict the salaries of people with 2, 12 and 80 years work experience, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:16.604128Z",
     "start_time": "2019-11-26T15:28:16.595386Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Predictions are now made and the model is scored\n",
    "predictions = lr_model.predict(X_test)\n",
    "r2_score = lr_model.score(X_test, y_test)\n",
    "print(f'The model score is {r2_score}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### The model score is the proportion of y (salary) variance as explained by indivudual variables in the model. It is an indication of the the goodness of fit of the model and measures how well unseen data will be predicted by the model. This means that the model does not fit the data very well, predicting only 45. 44% of the salaries correctly . It can be said that the model is underfitting the data.\n",
    "\n",
    "##### The random state parameter is altered a few times to try imporve the score and very little positive change results from this. The model is further evaluated and other attempts are made at improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:17.708203Z",
     "start_time": "2019-11-26T15:28:17.690803Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_vs_actual = pd.DataFrame({'Years_worked': X_test.flatten(), 'Actual': y_test.flatten(), 'Predicted': predictions.flatten()})\n",
    "pred_vs_actual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:19.168314Z",
     "start_time": "2019-11-26T15:28:18.898788Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The actual and prediced values are plotted \n",
    "plt.scatter(pred_vs_actual['Years_worked'], pred_vs_actual['Actual'], c = 'b', label = 'Actual salaries')\n",
    "plt.plot(pred_vs_actual['Years_worked'], pred_vs_actual['Predicted'], c = 'r', label = 'Predicted salaries regressor')\n",
    "plt.xlabel('Years worked')\n",
    "plt.ylabel('Salary')\n",
    "plt.title('The Actual and Predicted salaries based on the number of years worked')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:19.948858Z",
     "start_time": "2019-11-26T15:28:19.938151Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predictions are made for people with 2, 12 and 80 years work experience \n",
    "predicted_salary_for_2_years_work_experience = lr_model.predict(reshape(2))\n",
    "actual_salary_for_2_years_work_experience = (salaries['salary'].loc[(salaries['yearsworked'] == 2)]).mean()\n",
    "print(f'The predicted salary for 2 years work experience is {predicted_salary_for_2_years_work_experience} and the actual mean salary for the same years worked is {actual_salary_for_2_years_work_experience}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:20.547851Z",
     "start_time": "2019-11-26T15:28:20.537716Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predicted_salary_for_12_years_work_experience = lr_model.predict(reshape(12))\n",
    "actual_salary_for_12_years_work_experience = (salaries['salary'].loc[(salaries['yearsworked'] == 12)]).mean()\n",
    "print(f'The predicted salary for 12 years work experience is {predicted_salary_for_12_years_work_experience} and the actual mean salary for the same years worked is {actual_salary_for_12_years_work_experience}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:21.332276Z",
     "start_time": "2019-11-26T15:28:21.322421Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predicted_salary_for_80_years_work_experience = lr_model.predict(reshape(80))\n",
    "actual_salary_for_80_years_work_experience = (salaries['salary'].loc[(salaries['yearsworked'] == 80)]).mean()\n",
    "print(f'The predicted salary for 80 years work experience is {predicted_salary_for_80_years_work_experience} and the actual mean salary for the same years worked is {actual_salary_for_80_years_work_experience}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### The predicted and actual salaries are not too far off for 2 and 12 and years worked. The predicted salary for 80 years worked however is unexepcted considering there was no actual data provided for that input. The predicted value is made using the model fit line which, as already observed is scoring quite poorly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Model Evaluation: the model metrics are analysed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:23.287943Z",
     "start_time": "2019-11-26T15:28:23.281699Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_absolute_error = metrics.mean_absolute_error(y_test, predictions)\n",
    "print(mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### This metric measures the sum of the absolute difference between each predicted value and the true value in the dataset and then divides this sum by the total number of samples in the dataset. It measures the overall error in the model. The value seen above is very large and further confirms that the model is not ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:24.913514Z",
     "start_time": "2019-11-26T15:28:24.905843Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error = metrics.mean_squared_error(y_test, predictions)\n",
    "print(mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### This metric measures the squared sum of the absolute difference between each predicted value and the true value in the dataset and then divides this sum by the total number of samples in the dataset. It measures the overall error in the model.The square sum exaggereates the error and allows one to quickly pick up when a model is performing poorly as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:26.789801Z",
     "start_time": "2019-11-26T15:28:26.779699Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "explained_variance_score = metrics.explained_variance_score(y_test, predictions)\n",
    "print(explained_variance_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### This metric has a maximum value of 1. This occurs when the variance between the difference in the actual and predicted values divided by the variance of actual values is equal to zero. The explained variance of the model is 0.48. This means that the the variance ratio is 0. 52 and thus the model has still not accounted for enough of the variance in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Model Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### In attempts to impove the model, the following is done. First, an end to end pipeline is created that scales the data and creates an instance of the regressor.  The pipeline is then passed into a function that prints the r2 cross validation scores. Finally, the GridSearch method is also used to find the scores, estimators and parameters that would improve the model and return the best results. The GridSearch does not apply a cross validation initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:30.568706Z",
     "start_time": "2019-11-26T15:28:30.561958Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    '''The function below will be used to create an end-to-end pipeline that will be passed into the\n",
    "    GridSearch method'''\n",
    "    estimator = [('scaler', StandardScaler()), ('regressor', LinearRegression())]\n",
    "    pipeline = Pipeline(estimator).fit(X_train, y_train)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:31.315289Z",
     "start_time": "2019-11-26T15:28:31.301383Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create an instance of pipeline in order to run a cross validation\n",
    "pipe = pipeline().fit(X_train, y_train)\n",
    "\n",
    "# Get the parameters of the instance created\n",
    "parameters = pipe.get_params()\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:31.984141Z",
     "start_time": "2019-11-26T15:28:31.978054Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a function to display the scores for each fold during cross validation\n",
    "def print_scores(pipeline):\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, scoring = 'r2', cv = 3)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:32.756972Z",
     "start_time": "2019-11-26T15:28:32.737606Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_scores(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### In the first model, the data is split 80/20 with 80% of the data being allocated to training whilst 20% of the data is used for testing and returns a score 0f 45. 44%. Since the model has been given much more data, a higher score is as expected.\n",
    "\n",
    "##### A pipeline is created and the same 80% is used to run a cross validation of the model with 3 folds. Each model built using the cross_val_score method now uses 66% of the data for training  and  33% for testing. Because the model was trained on an original 80/20 split, this results in each model built during validation using 0.8*0.66=0.528 (52.8%) of the original data. \n",
    "\n",
    "##### The number of samples in the dataset are such the any number greater than 2 for k divides the data unevenly and each fold will not get an equal distribution of data. The data is continuous and thus the k-fold method is not stratified. \n",
    "\n",
    "##### Grid search is now implemented to search for optimal parameters. This is done with no cross validation so that the model is exposed to more data during the training process. When cv=None, or when it not passed as an argument, GridSearchCV will default to cv=3. I set it to cv = 1 to avoid any cross validation during the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:35.035468Z",
     "start_time": "2019-11-26T15:28:34.994708Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# GridSearch \n",
    "\n",
    "parameter_grid = {'regressor__fit_intercept': [True, False], 'regressor__normalize': [True, False]}\n",
    "\n",
    "grid_lr = GridSearchCV(pipe, parameter_grid, scoring = 'r2', cv = [(slice(None), slice(None))], verbose = 0)\n",
    "grid_search_lr_model = grid_lr.fit(X_train, y_train)\n",
    "grid_search_predictions = grid_lr.predict(X_test)\n",
    "grid_estimator = grid_lr.best_estimator_\n",
    "grid_score = grid_lr.best_score_\n",
    "grid_params = grid_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:36.490238Z",
     "start_time": "2019-11-26T15:28:36.482398Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The GridSearch results are displayed and interpreted\n",
    "print(f'Best estimator:{grid_estimator}.')\n",
    "print(f'Best score:{grid_score}.')\n",
    "print(f'Best parameters:{grid_params}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### The GridSearch above returns a best score of 37.08% which is lower than the original score from splitting  the data 80/20. This model still grossly underfits the data which leads me to believe that the selected model may not be the best one nor does it accurately explain the variance in the data. I would recommend that another linear model(maybe a classification) be considered for this dataset. It also speaks to how the linearity observed could be misleading. The correlation matrix below shows that there is a a stronger positive correlation with the salary and position versus the relationship observed between the salary and years worked/ ranked as suggested in the original assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T15:28:38.818184Z",
     "start_time": "2019-11-26T15:28:38.786228Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A correlation matrix is drawn\n",
    "salaries.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
